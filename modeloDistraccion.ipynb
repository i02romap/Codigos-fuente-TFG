{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTRZoOkB-v2-"
      },
      "source": [
        "##Previo al modelo\n",
        "\n",
        "Descarga las librerias necesarias (de colab) y saca los datasets de los repositorios necesarios\n",
        "(elegir el dataset qué se descargará más abajo y sustituir las rutas donde hagan falta)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VIWwwLd4zfrl"
      },
      "outputs": [],
      "source": [
        "!pip install timm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RA8Y8Qvnzh3M"
      },
      "outputs": [],
      "source": [
        "#!git clone https://github.com/i02romap/D3Sdataset\n",
        "#!git clone https://github.com/i02romap/yawn_eye_dataset\n",
        "#!git clone https://github.com/i02romap/distractedDataset\n",
        "!git clone https://github.com/i02romap/datasetMezcla"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cb3Rs3lDHgTR"
      },
      "source": [
        "##Cargar librerias y crear clases para datasets y dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JfNxs5oTHKlU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "import timm\n",
        "import torchvision.models as models\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sys\n",
        "from tqdm.notebook import tqdm\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from glob import glob\n",
        "import os\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "print('System Version:', sys.version)\n",
        "print('PyTorch version', torch.__version__)\n",
        "print('Torchvision version', torchvision.__version__)\n",
        "print('Numpy version', np.__version__)\n",
        "print('Pandas version', pd.__version__)\n",
        "print('Timm version', timm.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0NfRBABSH286"
      },
      "outputs": [],
      "source": [
        "class DistractionDataset(Dataset):\n",
        "    #data_dir -> where our data is sitting\n",
        "    def __init__ (self, data_dir, transform=None):\n",
        "        self.data = ImageFolder(data_dir, transform=transform)\n",
        "\n",
        "    def __len__ (self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]\n",
        "\n",
        "    @property\n",
        "    def classes(self):\n",
        "        return self.data.classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31vLeDVrnM2u"
      },
      "source": [
        "##Crear y entrenar modelo\n",
        "\n",
        "(Elegir modelo aquí e hiperparámetros del entrenamiento más abajo)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import timm\n",
        "import torchvision.models as models\n",
        "\n",
        "modelo = 3\n",
        "#1 - mobilenet\n",
        "#2 - efficientnet\n",
        "#3 - densenet\n",
        "#4 - squeezenet\n",
        "pretrain = 1\n",
        "#1 - true\n",
        "#0 - false\n",
        "\n",
        "class distractedClassifier(nn.Module):\n",
        "    def __init__(self, num_clases=2):\n",
        "        super(distractedClassifier, self).__init__()\n",
        "\n",
        "        if modelo == 1:\n",
        "          if pretrain == 1:\n",
        "            self.base_model=timm.create_model('tf_mobilenetv3_large_100', pretrained=True)\n",
        "            enet_out_size=self.base_model.classifier.in_features\n",
        "\n",
        "            self.base_model.classifier = nn.Sequential(\n",
        "              nn.Linear(enet_out_size, num_clases)\n",
        "            )\n",
        "          else:\n",
        "            self.base_model=timm.create_model('tf_mobilenetv3_large_100', pretrained=False)\n",
        "            enet_out_size=self.base_model.classifier.in_features\n",
        "\n",
        "            self.base_model.classifier = nn.Sequential(\n",
        "              nn.Linear(enet_out_size, num_clases)\n",
        "            )\n",
        "\n",
        "\n",
        "        if modelo == 2:\n",
        "          if pretrain == 1:\n",
        "            self.base_model=timm.create_model('efficientnet_b0', pretrained=True)\n",
        "            enet_out_size=self.base_model.classifier.in_features\n",
        "\n",
        "            self.base_model.classifier = nn.Sequential(\n",
        "              nn.Linear(enet_out_size, num_clases)\n",
        "            )\n",
        "          else:\n",
        "            self.base_model=timm.create_model('efficientnet_b0', pretrained=False)\n",
        "            enet_out_size=self.base_model.classifier.in_features\n",
        "\n",
        "            self.base_model.classifier = nn.Sequential(\n",
        "              nn.Linear(enet_out_size, num_clases)\n",
        "            )\n",
        "\n",
        "\n",
        "        if modelo == 3:\n",
        "          if pretrain == 1:\n",
        "            self.base_model=timm.create_model('densenet121', pretrained=True)\n",
        "            enet_out_size=self.base_model.classifier.in_features\n",
        "\n",
        "            self.base_model.classifier = nn.Sequential(\n",
        "              nn.Linear(enet_out_size, num_clases)\n",
        "            )\n",
        "          else:\n",
        "            self.base_model=timm.create_model('efficientnet_b0', pretrained=False)\n",
        "            enet_out_size=self.base_model.classifier.in_features\n",
        "\n",
        "            self.base_model.classifier = nn.Sequential(\n",
        "              nn.Linear(enet_out_size, num_clases)\n",
        "            )\n",
        "\n",
        "\n",
        "        if modelo == 4:\n",
        "          if pretrain == 1:\n",
        "            self.base_model = models.squeezenet1_1(pretrained=True)\n",
        "            for param in self.base_model.parameters():\n",
        "                param.requires_grad = False\n",
        "            self.base_model.classifier[1] = nn.Conv2d(512, num_clases, kernel_size=1)\n",
        "            self.base_model.num_classes = num_clases\n",
        "          else:\n",
        "            self.base_model = models.squeezenet1_1(pretrained=False)\n",
        "            for param in self.base_model.parameters():\n",
        "                param.requires_grad = False\n",
        "            self.base_model.classifier[1] = nn.Conv2d(512, num_clases, kernel_size=1)\n",
        "            self.base_model.num_classes = num_clases\n",
        "\n",
        "    def forward(self, x):\n",
        "       return self.base_model(x)\n"
      ],
      "metadata": {
        "id": "lucVYmxz8HDl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=distractedClassifier(num_clases=2)"
      ],
      "metadata": {
        "id": "0f7ookqT6o-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeNjwIWc2Me7"
      },
      "source": [
        "####bucle de entrenamiento\n",
        "\n",
        "(Modificar hiperparametros de training aquí)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajq92opo2rEz"
      },
      "source": [
        "loss function y optimizador"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "vnjeAAn8zkEF"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128,128)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "train_dir='/content/datasetMezcla/train'\n",
        "valid_dir='/content/datasetMezcla/validation'\n",
        "test_dir='/content/datasetMezcla/test'\n",
        "\n",
        "train_dataset = DistractionDataset(train_dir, transform)\n",
        "valid_dataset = DistractionDataset(valid_dir, transform)\n",
        "test_dataset = DistractionDataset(test_dir, transform)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset , batch_size = 32 , shuffle = True)\n",
        "valid_dataloader = DataLoader(valid_dataset , batch_size = 32 , shuffle = True)\n",
        "test_dataloader = DataLoader(test_dataset , batch_size = 32 , shuffle = True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_accuracy(model, data_loader, device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in data_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return 100 * correct / total"
      ],
      "metadata": {
        "id": "kEWvi8Yexc_9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XiIKLoppz7V_"
      },
      "source": [
        "entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses, val_losses = [],[]\n",
        "train_accs, val_accs= [] , []\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "model = distractedClassifier(num_clases=2)\n",
        "model.to(device)\n",
        "\n",
        "loss_funct = nn.CrossEntropyLoss()\n",
        "optimizador = optim.Adam(model.parameters(), lr=0.002)"
      ],
      "metadata": {
        "id": "xhssH2SwVmKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JEeFLn8VKeOA"
      },
      "outputs": [],
      "source": [
        "num_epochs=1\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  model.train()\n",
        "  running_loss=0.0\n",
        "  for images, labels in tqdm(train_dataloader, desc='Training loop'):\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "    optimizador.zero_grad()\n",
        "    outputs=model(images)\n",
        "    loss = loss_funct(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizador.step()\n",
        "    running_loss+=loss.item()*labels.size(0)\n",
        "  train_loss= running_loss/len(train_dataloader.dataset)\n",
        "  train_losses.append(train_loss)\n",
        "  train_acc = calculate_accuracy(model, train_dataloader, device)\n",
        "  train_accs.append(train_acc)\n",
        "\n",
        "  model.eval()\n",
        "  running_loss=0.0\n",
        "  with torch.no_grad():\n",
        "    for images, labels in tqdm(valid_dataloader, desc='Validation loop'):\n",
        "      images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "      outputs=model(images)\n",
        "      loss=loss_funct(outputs, labels)\n",
        "      running_loss+=loss.item()*labels.size(0)\n",
        "  val_loss=running_loss/len(valid_dataloader.dataset)\n",
        "  val_losses.append(val_loss)\n",
        "  val_acc = calculate_accuracy(model, valid_dataloader, device)\n",
        "  val_accs.append(val_acc)\n",
        "\n",
        "  print(f\"Epoch {epoch+1}/{num_epochs} - Train loss: {train_loss}, Validation loss: {val_loss}, Training accuracy: {train_acc}, Validation accuracy: {val_acc}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1NXfSZUuSgK1"
      },
      "outputs": [],
      "source": [
        "#visualizar loss\n",
        "plt.plot(train_losses, label='train loss')\n",
        "plt.plot(val_losses, label='valid loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#visualizar accuracy\n",
        "plt.plot(train_accs, label='train accuracry')\n",
        "plt.plot(val_accs, label='valid accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "p3IBeNkUyOGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWa7IVpOYisS"
      },
      "source": [
        "#Evaluación del modelo\n",
        "Obtener la matriz de confusión y accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "219-bpCvYk7F"
      },
      "outputs": [],
      "source": [
        "# Load and preprocess the image\n",
        "def preprocess_image(image_path, transform):\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    return image, transform(image).unsqueeze(0)\n",
        "\n",
        "# Predict using the model\n",
        "def predict(model, image_tensor, device):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        image_tensor = image_tensor.to(device)\n",
        "        outputs = model(image_tensor)\n",
        "        probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
        "        probabilities = probabilities[:, :2]\n",
        "    return probabilities.cpu().numpy().flatten()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_WdYzhDoPcs"
      },
      "outputs": [],
      "source": [
        "test_images = glob('/content/datasetMezcla/test/*/*')\n",
        "clases_reales = []\n",
        "clases_predichas = []\n",
        "for item in test_images:\n",
        "    if item.endswith('.jpg'):\n",
        "      clases_reales.append(os.path.basename(os.path.dirname(item)))\n",
        "\n",
        "      original_image, image_tensor = preprocess_image(item, transform)\n",
        "      probabilities = predict(model, image_tensor, device)\n",
        "      class_names = dataset.classes\n",
        "\n",
        "      clases_predichas.append(class_names[np.argmax(probabilities)])\n",
        "\n",
        "print(clases_reales)\n",
        "print(clases_predichas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "On1BBpwosEbT"
      },
      "outputs": [],
      "source": [
        "# Obtener todas las clases únicas\n",
        "clases = np.unique(clases_reales+clases_predichas)\n",
        "\n",
        "# Crear la matriz de confusión\n",
        "confusion = confusion_matrix(clases_reales, clases_predichas, labels=clases)\n",
        "\n",
        "print(\"Matriz de Confusión:\")\n",
        "print(confusion)\n",
        "print(np.sum(confusion))\n",
        "\n",
        "\n",
        "\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=confusion, display_labels=clases)\n",
        "disp.plot()\n",
        "\n",
        "\n",
        "print(f\"Accuracy del test: {accuracy_score(clases_reales, clases_predichas)*100}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Descargar Modelo\n",
        "\n",
        "Guardar y descargar el fichero .pth del modelo entrenado"
      ],
      "metadata": {
        "id": "TmL5roMIxrio"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "torch.save(model.state_dict(), 'modeloDescarga.pth')\n",
        "\n",
        "files.download('modeloDescarga.pth')"
      ],
      "metadata": {
        "id": "h0BM663nxqbD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "18d2d305-8b04-4d58-e4f1-180d6619dd70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_46890c79-1b2d-4e16-afe2-2092f2703903\", \"modeloDescarga.pth\", 16354326)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Guardar el dataset con las carpetas de las clases  \n",
        "Para datasets que vinieran sin modificar\n",
        "\n",
        "(se puede hacer esto directamente, solo necesitando hacer la parte de Previo al modelo)"
      ],
      "metadata": {
        "id": "yLHrhmsWbrLM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r datasetEditado.zip /content/yawn_eye_dataset"
      ],
      "metadata": {
        "id": "7Bf6ek_SbwRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('datasetEditado.zip')\n"
      ],
      "metadata": {
        "id": "psjqxXz0bzRI"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "QTRZoOkB-v2-",
        "orGdx04DUVqp",
        "bSb_dwY8UXUz",
        "Cb3Rs3lDHgTR",
        "BWa7IVpOYisS",
        "yLHrhmsWbrLM"
      ],
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}